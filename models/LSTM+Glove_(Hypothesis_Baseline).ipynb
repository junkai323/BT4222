{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEa_RQw_0NyS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import logging\n",
    "\n",
    "import pickle\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g0iaKg81QyG"
   },
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VkIfieB13WG",
    "outputId": "a69b4644-3e03-4ecb-900e-d0899be896fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qu1CI9ex1TB4"
   },
   "outputs": [],
   "source": [
    "full_clean_df = pd.read_excel(\"../data/full_clean_df.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYbxrImx0ebe"
   },
   "outputs": [],
   "source": [
    "labels_name_list = ['NotHate', 'Racist', 'Sexist', 'Homophobe', 'Religion', 'OtherHate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSn9K0pa93qg",
    "outputId": "5df48413-9e0d-43dd-dc38-d9c71847ea59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length of tweet\n",
    "max([len(i) for i in full_clean_df['tweets_train'].apply(lambda x: x.split(' '))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmPwKkuE2LfA"
   },
   "source": [
    "**Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZ2GFYyk2KwK"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(full_clean_df['tweets_train'], np.array(full_clean_df[labels_name_list]), test_size=0.33, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NW6OWmNonv8h"
   },
   "outputs": [],
   "source": [
    "X = X_train\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2KfjIXx2V4N",
    "outputId": "6b9b6d12-2785-4417-c524-f2227eaba289"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95995,)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vj1N4-4REDsu"
   },
   "source": [
    "Define function to plot history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rbe8YuZG2X9W"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # Plot loss and AUC \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.epoch, history.history['val_loss'], 'g-', label='Validation data')\n",
    "    plt.plot(history.epoch, history.history['loss'], 'r--', label='Training data')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Loss on training/validation data')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.epoch, history.history['val_auc'], 'g-', label='Validation data')\n",
    "    plt.plot(history.epoch, history.history['auc'], 'r--', label='Training data')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('AUC on training/validation data')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Co5TgclfAW9j"
   },
   "outputs": [],
   "source": [
    "# Tokenize Text (Represent each word by a number)\n",
    "max_features = 10000\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Keep all tweets to exact 30 words\n",
    "maxlen = 30\n",
    "\n",
    "train_encoded = tokenizer.texts_to_sequences(X)\n",
    "train_padded = sequence.pad_sequences(train_encoded, maxlen=maxlen)\n",
    "\n",
    "test_encoded = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = sequence.pad_sequences(test_encoded, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5031vd-LB6m7",
    "outputId": "b1bdc853-2254-4f95-bf80-437cc0fd2164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-21 13:30:54--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
      "--2021-04-21 13:30:54--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
      "--2021-04-21 13:30:55--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1520408563 (1.4G) [application/zip]\n",
      "Saving to: ‘glove.twitter.27B.zip’\n",
      "\n",
      "glove.twitter.27B.z 100%[===================>]   1.42G  5.07MB/s    in 4m 46s  \n",
      "\n",
      "2021-04-21 13:35:42 (5.06 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-21ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
      "Archive:  glove.twitter.27B.zip\n",
      "  inflating: glove.twitter.27B.25d.txt  \n",
      "  inflating: glove.twitter.27B.50d.txt  \n",
      "  inflating: glove.twitter.27B.100d.txt  \n",
      "  inflating: glove.twitter.27B.200d.txt  \n"
     ]
    }
   ],
   "source": [
    "# Install gloVe twitter\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "!sudo apt install unzip\n",
    "!unzip glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1tNQNilAW66"
   },
   "outputs": [],
   "source": [
    "# Load the embedding file\n",
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "EMBEDDING_FILE = 'glove.twitter.27B.100d.txt'\n",
    "# Map each word to its word vector\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, 'r', encoding='UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZBEyUsTAW48",
    "outputId": "2dbd1031-5946-4554-ac70-6af3ed8f8f34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "#change below line if computing normal stats is too slow\n",
    "embedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC4GZTo5pDlx"
   },
   "source": [
    "# 5-folds Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kN99agUDpKrL"
   },
   "source": [
    "**Compile Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMC1anTwRrlR"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 5\n",
    "embed_size = 100\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7q2vXKdpIwL"
   },
   "outputs": [],
   "source": [
    "def compile_model(max_features=max_features, embed_size=100, embedding_matrix=embedding_matrix, maxlen=maxlen):\n",
    "  # Define the Neural Network\n",
    "  model = Sequential()\n",
    "  # Non-trainable embeddidng layer\n",
    "  model.add(Embedding(max_features, output_dim=embed_size, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "  # LSTM \n",
    "  model.add(LSTM(128, return_sequences=True))\n",
    "  model.add(Dropout(0.15))\n",
    "  model.add(LSTM(64))\n",
    "  model.add(Dropout(0.15))\n",
    "  model.add(Dense(6, activation='sigmoid'))\n",
    "  model.summary()\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Precision', 'Recall', 'AUC'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFM7BpUJpC0M"
   },
   "outputs": [],
   "source": [
    "def one_fold(X_train, y_train, X_val, y_val, batch_size, epochs, es):\n",
    "  model = compile_model()\n",
    "\n",
    "  history = model.fit(X_train, y_train, batch_size = batch_size, validation_data = (X_val, y_val), epochs=epochs, callbacks=[es])\n",
    "  y_pred = model.predict(X_val)\n",
    "  predictions = [[1 if i >=0.3 else 0 for i in pred] for pred in y_pred]\n",
    "\n",
    "  score = metrics.f1_score(y_val, predictions, average='macro')\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34zEbA04pCqq",
    "outputId": "2b23195f-7169-46cb-fbe2-4cae157b3840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 37s 17ms/step - loss: 0.3540 - precision: 0.8297 - recall: 0.6099 - auc: 0.8792 - val_loss: 0.2733 - val_precision: 0.8786 - val_recall: 0.6691 - val_auc: 0.9324\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2769 - precision: 0.8504 - recall: 0.6890 - auc: 0.9307 - val_loss: 0.2654 - val_precision: 0.8859 - val_recall: 0.6733 - val_auc: 0.9364\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2697 - precision: 0.8646 - recall: 0.6887 - auc: 0.9342 - val_loss: 0.2616 - val_precision: 0.8716 - val_recall: 0.6903 - val_auc: 0.9383\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2648 - precision: 0.8727 - recall: 0.6879 - auc: 0.9364 - val_loss: 0.2606 - val_precision: 0.8603 - val_recall: 0.7033 - val_auc: 0.9388\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2637 - precision: 0.8719 - recall: 0.6913 - auc: 0.9370 - val_loss: 0.2586 - val_precision: 0.8794 - val_recall: 0.6853 - val_auc: 0.9398\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 8s 17ms/step - loss: 0.3536 - precision: 0.8342 - recall: 0.5972 - auc: 0.8773 - val_loss: 0.2761 - val_precision: 0.8815 - val_recall: 0.6636 - val_auc: 0.9306\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2788 - precision: 0.8491 - recall: 0.6854 - auc: 0.9299 - val_loss: 0.2662 - val_precision: 0.8646 - val_recall: 0.6931 - val_auc: 0.9357\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2715 - precision: 0.8589 - recall: 0.6902 - auc: 0.9331 - val_loss: 0.2621 - val_precision: 0.8881 - val_recall: 0.6791 - val_auc: 0.9375\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2676 - precision: 0.8639 - recall: 0.6903 - auc: 0.9357 - val_loss: 0.2600 - val_precision: 0.8850 - val_recall: 0.6844 - val_auc: 0.9387\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2648 - precision: 0.8707 - recall: 0.6892 - auc: 0.9366 - val_loss: 0.2591 - val_precision: 0.8741 - val_recall: 0.6953 - val_auc: 0.9393\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 8s 17ms/step - loss: 0.3522 - precision: 0.8414 - recall: 0.5900 - auc: 0.8768 - val_loss: 0.2798 - val_precision: 0.8729 - val_recall: 0.6635 - val_auc: 0.9289\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2766 - precision: 0.8561 - recall: 0.6853 - auc: 0.9305 - val_loss: 0.2728 - val_precision: 0.8755 - val_recall: 0.6729 - val_auc: 0.9325\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2683 - precision: 0.8602 - recall: 0.6920 - auc: 0.9348 - val_loss: 0.2684 - val_precision: 0.8732 - val_recall: 0.6795 - val_auc: 0.9346\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2639 - precision: 0.8710 - recall: 0.6919 - auc: 0.9366 - val_loss: 0.2665 - val_precision: 0.8740 - val_recall: 0.6819 - val_auc: 0.9356\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2626 - precision: 0.8747 - recall: 0.6904 - auc: 0.9373 - val_loss: 0.2656 - val_precision: 0.8764 - val_recall: 0.6820 - val_auc: 0.9363\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 8s 17ms/step - loss: 0.3486 - precision: 0.8506 - recall: 0.6016 - auc: 0.8816 - val_loss: 0.2774 - val_precision: 0.8786 - val_recall: 0.6627 - val_auc: 0.9303\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2767 - precision: 0.8552 - recall: 0.6848 - auc: 0.9305 - val_loss: 0.2679 - val_precision: 0.8637 - val_recall: 0.6920 - val_auc: 0.9352\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2701 - precision: 0.8620 - recall: 0.6912 - auc: 0.9337 - val_loss: 0.2640 - val_precision: 0.8809 - val_recall: 0.6799 - val_auc: 0.9371\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2660 - precision: 0.8685 - recall: 0.6896 - auc: 0.9357 - val_loss: 0.2622 - val_precision: 0.8768 - val_recall: 0.6873 - val_auc: 0.9379\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2607 - precision: 0.8722 - recall: 0.6931 - auc: 0.9384 - val_loss: 0.2609 - val_precision: 0.8869 - val_recall: 0.6789 - val_auc: 0.9388\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 30, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 30, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 8s 17ms/step - loss: 0.3516 - precision: 0.8467 - recall: 0.5885 - auc: 0.8774 - val_loss: 0.2767 - val_precision: 0.8716 - val_recall: 0.6687 - val_auc: 0.9308\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2770 - precision: 0.8552 - recall: 0.6864 - auc: 0.9303 - val_loss: 0.2684 - val_precision: 0.8860 - val_recall: 0.6704 - val_auc: 0.9351\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2697 - precision: 0.8612 - recall: 0.6899 - auc: 0.9339 - val_loss: 0.2647 - val_precision: 0.8888 - val_recall: 0.6711 - val_auc: 0.9368\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2638 - precision: 0.8705 - recall: 0.6922 - auc: 0.9370 - val_loss: 0.2636 - val_precision: 0.8908 - val_recall: 0.6713 - val_auc: 0.9376\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.2614 - precision: 0.8732 - recall: 0.6930 - auc: 0.9382 - val_loss: 0.2614 - val_precision: 0.8737 - val_recall: 0.6882 - val_auc: 0.9386\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_padded):\n",
    "  X_train, X_val = train_padded[train_index], train_padded[val_index]\n",
    "  y_train, y_val = y[train_index], y[val_index]\n",
    "  f1_scores.append(one_fold(X_train, y_train, X_val, y_val, batch_size = 256, epochs=5, es=es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjufzRSIpCnE",
    "outputId": "11552749-bf0a-4fd4-dff7-a85cb1ff918f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5503131007793429,\n",
       " 0.5536645807247731,\n",
       " 0.543105274882358,\n",
       " 0.5556589535657163,\n",
       " 0.5508641887640409]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42Jxfjx2pCjG"
   },
   "outputs": [],
   "source": [
    "# Save f1_scores\n",
    "with open(\"lstm_baseline.txt\", \"wb\") as fp:\n",
    "  pickle.dump(f1_scores, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siNg2sX2wczF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbKyGE2MwzAv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "(FINAL) LSTM+Glove (Hypothesis - Baseline)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
