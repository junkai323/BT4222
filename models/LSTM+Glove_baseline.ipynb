{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEa_RQw_0NyS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import Dropout, SpatialDropout1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import logging\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g0iaKg81QyG"
   },
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VkIfieB13WG",
    "outputId": "828cbffb-84a7-4ab1-ba5d-09221370d70a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qu1CI9ex1TB4"
   },
   "outputs": [],
   "source": [
    "full_clean_df = pd.read_excel(\"../data/full_clean_df.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYbxrImx0ebe"
   },
   "outputs": [],
   "source": [
    "labels_name_list = ['NotHate', 'Racist', 'Sexist', 'Homophobe', 'Religion', 'OtherHate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSn9K0pa93qg",
    "outputId": "4948fbfb-2417-4f02-f235-95b86d949ca5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length of tweet\n",
    "max([len(i) for i in full_clean_df['tweets_train'].apply(lambda x: x.split(' '))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmPwKkuE2LfA"
   },
   "source": [
    "**Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZ2GFYyk2KwK"
   },
   "outputs": [],
   "source": [
    "X, X_test, y, y_test =  train_test_split(full_clean_df['tweets_train'], full_clean_df[labels_name_list], test_size=0.33, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBzdsRAK2Oen"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2KfjIXx2V4N",
    "outputId": "d500eb0f-ff29-4d31-9fc1-7924842ea32f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64316,)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vj1N4-4REDsu"
   },
   "source": [
    "Define function to plot history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rbe8YuZG2X9W"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # Plot loss and AUC \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.epoch, history.history['val_loss'], 'g-', label='Validation data')\n",
    "    plt.plot(history.epoch, history.history['loss'], 'r--', label='Training data')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Loss on training/validation data')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.epoch, history.history['val_auc'], 'g-', label='Validation data')\n",
    "    plt.plot(history.epoch, history.history['auc'], 'r--', label='Training data')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('AUC on training/validation data')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Co5TgclfAW9j"
   },
   "outputs": [],
   "source": [
    "# Tokenize Text (Represent each word by a number)\n",
    "max_features = 10000\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "# Keep all tweets to exact 30 words\n",
    "maxlen = 30\n",
    "tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "\n",
    "tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)\n",
    "\n",
    "val_encoded = tokenizer.texts_to_sequences(X_val)\n",
    "val_padded = sequence.pad_sequences(val_encoded, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5031vd-LB6m7"
   },
   "outputs": [],
   "source": [
    "# Install gloVe twitter\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "!sudo apt install unzip\n",
    "!unzip glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1tNQNilAW66"
   },
   "outputs": [],
   "source": [
    "# Load the embedding file\n",
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "EMBEDDING_FILE = 'glove.twitter.27B.100d.txt'\n",
    "# Map each word to its word vector\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, 'r', encoding='UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZBEyUsTAW48",
    "outputId": "d2b7a0b0-0e7f-47bd-d16a-83ab2a6d308d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "#change below line if computing normal stats is too slow\n",
    "embedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMC1anTwRrlR"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 5\n",
    "embed_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWj-xgG-RwrQ",
    "outputId": "7b30dfee-5874-4878-f536-33493a10300b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 30, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Neural Network\n",
    "model = Sequential()\n",
    "# Non-trainable embeddidng layer\n",
    "model.add(Embedding(max_features, output_dim=embed_size, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "# LSTM \n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Precision', 'Recall', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1GVh9bQoXCT",
    "outputId": "79bd4956-6978-4ffd-99df-5459a0a00f2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "252/252 [==============================] - 43s 42ms/step - loss: 0.3519 - precision: 0.8694 - recall: 0.5914 - auc: 0.8775 - val_loss: 0.2801 - val_precision: 0.8814 - val_recall: 0.6538 - val_auc: 0.9288\n",
      "Epoch 2/5\n",
      "252/252 [==============================] - 9s 35ms/step - loss: 0.2804 - precision: 0.8518 - recall: 0.6796 - auc: 0.9286 - val_loss: 0.2692 - val_precision: 0.8702 - val_recall: 0.6847 - val_auc: 0.9343\n",
      "Epoch 3/5\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.2698 - precision: 0.8609 - recall: 0.6915 - auc: 0.9342 - val_loss: 0.2662 - val_precision: 0.8723 - val_recall: 0.6845 - val_auc: 0.9354\n",
      "Epoch 4/5\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.2666 - precision: 0.8668 - recall: 0.6898 - auc: 0.9356 - val_loss: 0.2644 - val_precision: 0.8773 - val_recall: 0.6836 - val_auc: 0.9366\n",
      "Epoch 5/5\n",
      "252/252 [==============================] - 9s 34ms/step - loss: 0.2645 - precision: 0.8683 - recall: 0.6916 - auc: 0.9367 - val_loss: 0.2635 - val_precision: 0.8739 - val_recall: 0.6865 - val_auc: 0.9372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f18640bdc90>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "model.fit(X_train, y_train, batch_size = batch_size , validation_data = (val_padded,y_val) , epochs = epochs, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNXO7iyNkRmn"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(val_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0B32qQb-k-zM"
   },
   "outputs": [],
   "source": [
    "# function to find the best threshold \n",
    "def optimal_threshold(test, predictions):\n",
    "  thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "  threshold_df = pd.DataFrame({})\n",
    "  \n",
    "  for thres in thresholds:\n",
    "      pred = predictions.copy()\n",
    "    \n",
    "      pred[pred >= thres] = 1\n",
    "      pred[pred < thres] = 0\n",
    "    \n",
    "      precision = precision_score(test, pred, average='macro')\n",
    "      recall = recall_score(test, pred, average='macro')\n",
    "      f1 = f1_score(test, pred, average='macro')\n",
    "\n",
    "      df = pd.DataFrame({\n",
    "          'threshold': round(thres, 4),\n",
    "          'prediction': round(precision, 4),\n",
    "          'recall': round(recall, 4),\n",
    "          'f1': round(f1, 4)\n",
    "      }, index=[0])\n",
    "\n",
    "      threshold_df = threshold_df.append(df)\n",
    "    \n",
    "  return threshold_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "9gyZITUAlFDm",
    "outputId": "0efe70ff-2573-4393-fd90-5ac6b0c66925"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>prediction</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4617</td>\n",
       "      <td>0.7107</td>\n",
       "      <td>0.5147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>0.6478</td>\n",
       "      <td>0.5441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5927</td>\n",
       "      <td>0.6044</td>\n",
       "      <td>0.5454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6281</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.5316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6058</td>\n",
       "      <td>0.4002</td>\n",
       "      <td>0.4589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6511</td>\n",
       "      <td>0.3567</td>\n",
       "      <td>0.4195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.3693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7158</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4714</td>\n",
       "      <td>0.1277</td>\n",
       "      <td>0.1432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  prediction  recall      f1\n",
       "0        0.1      0.4617  0.7107  0.5147\n",
       "1        0.2      0.5945  0.6478  0.5441\n",
       "2        0.3      0.5927  0.6044  0.5454\n",
       "3        0.4      0.6281  0.5441  0.5316\n",
       "4        0.5      0.6058  0.4002  0.4589\n",
       "5        0.6      0.6511  0.3567  0.4195\n",
       "6        0.7      0.6867  0.3044  0.3693\n",
       "7        0.8      0.7158  0.2212  0.2738\n",
       "8        0.9      0.4714  0.1277  0.1432"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_threshold(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NSmFIgCkusj"
   },
   "outputs": [],
   "source": [
    "# optimal threshold = 0.3\n",
    "\n",
    "lstm_pred = [[1 if i >=0.3 else 0 for i in pred] for pred in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXkbU2Muk6-G",
    "outputId": "fa07b2f8-8d17-46b1-ab60-db2a69e1a3ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.930423  0.994508  0.961398     28950\n",
      "           1   0.449706  0.869879  0.592898      9837\n",
      "           2   0.494405  0.558878  0.524668      4348\n",
      "           3   0.693434  0.654523  0.673417      2388\n",
      "           4   0.500000  0.002137  0.004255       468\n",
      "           5   0.488132  0.546741  0.515777      4664\n",
      "\n",
      "   micro avg   0.703770  0.866489  0.776698     50655\n",
      "   macro avg   0.592683  0.604444  0.545402     50655\n",
      "weighted avg   0.743771  0.866489  0.788901     50655\n",
      " samples avg   0.723092  0.898850  0.773167     50655\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_val,  lstm_pred, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_rWjLsZBl9d",
    "outputId": "39758d29-31e0-4a37-c510-dc1df62fc263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.39133179708955457\n",
      "F1 score:  0.5454021878350711\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(y_val, lstm_pred))\n",
    "print('F1 score: ', f1_score(y_val, lstm_pred, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "(FINAL) LSTM+Glove_baseline",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
