{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEa_RQw_0NyS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import Dropout, SpatialDropout1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g0iaKg81QyG"
   },
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VkIfieB13WG",
    "outputId": "4b954c53-dd26-4910-d089-44d725b36083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qu1CI9ex1TB4"
   },
   "outputs": [],
   "source": [
    "full_clean_df = pd.read_excel(\"../data/full_clean_df.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYbxrImx0ebe"
   },
   "outputs": [],
   "source": [
    "labels_name_list = ['NotHate', 'Racist', 'Sexist', 'Homophobe', 'Religion', 'OtherHate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNR0s_02004t"
   },
   "outputs": [],
   "source": [
    "# Remove NaN\n",
    "full_clean_df = full_clean_df[full_clean_df['tweets_nig_train'].astype(str) != 'nan'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSn9K0pa93qg",
    "outputId": "21a8e44e-4bff-4937-8335-6a708dddff9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# max length of tweet\n",
    "maxlen = max([len(i) for i in full_clean_df['tweets_nig_train'].apply(lambda x: x.split(' '))])\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1f7zFu0z0wVi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmPwKkuE2LfA"
   },
   "source": [
    "**Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZ2GFYyk2KwK"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(full_clean_df['tweets_nig_train'], np.array(full_clean_df[labels_name_list]), test_size=0.33, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNdRrZZxhxUp"
   },
   "outputs": [],
   "source": [
    "X = X_train\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AW0j6vEignM8",
    "outputId": "d9dc9a85-27b1-427d-cdf7-758b628bf27b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95988,)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHHQ-NjsggQ2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vj1N4-4REDsu"
   },
   "source": [
    "Define function to plot history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rbe8YuZG2X9W"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # Plot loss and AUC \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.epoch, history.history['val_loss'], 'g-', label='Validation data')\n",
    "    plt.plot(history.epoch, history.history['loss'], 'r--', label='Training data')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Loss on training/validation data')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.epoch, history.history['val_auc'], 'g-', label='Validation data')\n",
    "    plt.plot(history.epoch, history.history['auc'], 'r--', label='Training data')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('AUC on training/validation data')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Co5TgclfAW9j"
   },
   "outputs": [],
   "source": [
    "# Tokenize Text (Represent each word by a number)\n",
    "max_features = 10000\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "train_encoded = tokenizer.texts_to_sequences(X)\n",
    "train_padded = sequence.pad_sequences(train_encoded, maxlen=maxlen)\n",
    "\n",
    "test_encoded = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = sequence.pad_sequences(test_encoded, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5031vd-LB6m7",
    "outputId": "babbce96-6b13-4816-e36e-c506c8e6ab1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-21 14:29:05--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
      "--2021-04-21 14:29:05--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
      "--2021-04-21 14:29:05--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1520408563 (1.4G) [application/zip]\n",
      "Saving to: ‘glove.twitter.27B.zip’\n",
      "\n",
      "glove.twitter.27B.z 100%[===================>]   1.42G  5.00MB/s    in 5m 6s   \n",
      "\n",
      "2021-04-21 14:34:11 (4.74 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-21ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
      "Archive:  glove.twitter.27B.zip\n",
      "  inflating: glove.twitter.27B.25d.txt  \n",
      "  inflating: glove.twitter.27B.50d.txt  \n",
      "  inflating: glove.twitter.27B.100d.txt  \n",
      "  inflating: glove.twitter.27B.200d.txt  \n"
     ]
    }
   ],
   "source": [
    "# Install gloVe twitter\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "!sudo apt install unzip\n",
    "!unzip glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1tNQNilAW66"
   },
   "outputs": [],
   "source": [
    "# Load the embedding file\n",
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "EMBEDDING_FILE = 'glove.twitter.27B.100d.txt'\n",
    "# Map each word to its word vector\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, 'r', encoding='UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZBEyUsTAW48",
    "outputId": "1abbff2d-2f6a-403e-eca5-245566c43348"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "#change below line if computing normal stats is too slow\n",
    "embedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg7fMUnkXJt4"
   },
   "source": [
    "# 5-folds Cross Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8JRj5QPX1q1"
   },
   "source": [
    "**Function to compile Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMC1anTwRrlR"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 5\n",
    "embed_size = 100\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWj-xgG-RwrQ"
   },
   "outputs": [],
   "source": [
    "def compile_model(max_features=max_features, embed_size=100, embedding_matrix=embedding_matrix, maxlen=maxlen):\n",
    "  # Define the Neural Network\n",
    "  model = Sequential()\n",
    "  # Non-trainable embeddidng layer\n",
    "  model.add(Embedding(max_features, output_dim=embed_size, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "  # LSTM \n",
    "  model.add(LSTM(128, return_sequences=True))\n",
    "  model.add(Dropout(0.15))\n",
    "  model.add(LSTM(64))\n",
    "  model.add(Dropout(0.15))\n",
    "  model.add(Dense(6, activation='sigmoid'))\n",
    "  model.summary()\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Precision', 'Recall', 'AUC'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rKhDooTYYRt"
   },
   "outputs": [],
   "source": [
    "def one_fold(X_train, y_train, X_val, y_val, batch_size, epochs, es):\n",
    "  model = compile_model()\n",
    "\n",
    "  history = model.fit(X_train, y_train, batch_size = batch_size, validation_data = (X_val, y_val), epochs=epochs, callbacks=[es])\n",
    "  y_pred = model.predict(X_val)\n",
    "  predictions = [[1 if i >=0.3 else 0 for i in pred] for pred in y_pred]\n",
    "\n",
    "  score = metrics.f1_score(y_val, predictions, average='macro')\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MfkCW0ZeaJ1i",
    "outputId": "2e276135-379f-41f0-b3d0-ec4baf6a925c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 24, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 24, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 38s 14ms/step - loss: 0.3548 - precision: 0.8331 - recall: 0.6106 - auc: 0.8767 - val_loss: 0.2758 - val_precision: 0.8472 - val_recall: 0.6984 - val_auc: 0.9318\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 0.2807 - precision: 0.8521 - recall: 0.6872 - auc: 0.9288 - val_loss: 0.2669 - val_precision: 0.8860 - val_recall: 0.6772 - val_auc: 0.9351\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2716 - precision: 0.8651 - recall: 0.6879 - auc: 0.9333 - val_loss: 0.2638 - val_precision: 0.8821 - val_recall: 0.6846 - val_auc: 0.9369\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2700 - precision: 0.8656 - recall: 0.6900 - auc: 0.9340 - val_loss: 0.2625 - val_precision: 0.8826 - val_recall: 0.6857 - val_auc: 0.9377\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2669 - precision: 0.8711 - recall: 0.6908 - auc: 0.9359 - val_loss: 0.2613 - val_precision: 0.8719 - val_recall: 0.6963 - val_auc: 0.9382\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 24, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 24, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 7s 14ms/step - loss: 0.3603 - precision: 0.8414 - recall: 0.5850 - auc: 0.8668 - val_loss: 0.2821 - val_precision: 0.8770 - val_recall: 0.6592 - val_auc: 0.9278\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2814 - precision: 0.8539 - recall: 0.6836 - auc: 0.9284 - val_loss: 0.2724 - val_precision: 0.8762 - val_recall: 0.6786 - val_auc: 0.9326\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2729 - precision: 0.8619 - recall: 0.6916 - auc: 0.9326 - val_loss: 0.2687 - val_precision: 0.8716 - val_recall: 0.6853 - val_auc: 0.9347\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2697 - precision: 0.8679 - recall: 0.6913 - auc: 0.9342 - val_loss: 0.2674 - val_precision: 0.8804 - val_recall: 0.6783 - val_auc: 0.9354\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2648 - precision: 0.8738 - recall: 0.6901 - auc: 0.9365 - val_loss: 0.2656 - val_precision: 0.8785 - val_recall: 0.6834 - val_auc: 0.9364\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 24, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 24, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 8s 15ms/step - loss: 0.3518 - precision: 0.8602 - recall: 0.5918 - auc: 0.8753 - val_loss: 0.2801 - val_precision: 0.8795 - val_recall: 0.6630 - val_auc: 0.9292\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2786 - precision: 0.8548 - recall: 0.6869 - auc: 0.9296 - val_loss: 0.2730 - val_precision: 0.8828 - val_recall: 0.6705 - val_auc: 0.9330\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2691 - precision: 0.8644 - recall: 0.6939 - auc: 0.9344 - val_loss: 0.2703 - val_precision: 0.8763 - val_recall: 0.6806 - val_auc: 0.9340\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2666 - precision: 0.8681 - recall: 0.6920 - auc: 0.9356 - val_loss: 0.2681 - val_precision: 0.8835 - val_recall: 0.6753 - val_auc: 0.9351\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2651 - precision: 0.8752 - recall: 0.6918 - auc: 0.9363 - val_loss: 0.2668 - val_precision: 0.8724 - val_recall: 0.6872 - val_auc: 0.9359\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 24, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 24, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 7s 15ms/step - loss: 0.3581 - precision: 0.8552 - recall: 0.5855 - auc: 0.8717 - val_loss: 0.2783 - val_precision: 0.8842 - val_recall: 0.6571 - val_auc: 0.9309\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2802 - precision: 0.8597 - recall: 0.6810 - auc: 0.9285 - val_loss: 0.2696 - val_precision: 0.8881 - val_recall: 0.6702 - val_auc: 0.9347\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 0.2740 - precision: 0.8647 - recall: 0.6875 - auc: 0.9319 - val_loss: 0.2659 - val_precision: 0.8845 - val_recall: 0.6760 - val_auc: 0.9364\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2686 - precision: 0.8694 - recall: 0.6885 - auc: 0.9347 - val_loss: 0.2643 - val_precision: 0.8711 - val_recall: 0.6918 - val_auc: 0.9373\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2644 - precision: 0.8732 - recall: 0.6939 - auc: 0.9366 - val_loss: 0.2632 - val_precision: 0.8861 - val_recall: 0.6793 - val_auc: 0.9377\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 24, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 24, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 24, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 7s 15ms/step - loss: 0.3482 - precision: 0.8715 - recall: 0.5972 - auc: 0.8809 - val_loss: 0.2790 - val_precision: 0.8751 - val_recall: 0.6675 - val_auc: 0.9297\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2800 - precision: 0.8523 - recall: 0.6844 - auc: 0.9295 - val_loss: 0.2708 - val_precision: 0.8700 - val_recall: 0.6896 - val_auc: 0.9339\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2705 - precision: 0.8661 - recall: 0.6907 - auc: 0.9336 - val_loss: 0.2680 - val_precision: 0.8761 - val_recall: 0.6867 - val_auc: 0.9349\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2675 - precision: 0.8749 - recall: 0.6877 - auc: 0.9351 - val_loss: 0.2662 - val_precision: 0.8744 - val_recall: 0.6913 - val_auc: 0.9358\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2647 - precision: 0.8744 - recall: 0.6899 - auc: 0.9367 - val_loss: 0.2648 - val_precision: 0.8691 - val_recall: 0.6975 - val_auc: 0.9367\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_padded):\n",
    "  X_train, X_val = train_padded[train_index], train_padded[val_index]\n",
    "  y_train, y_val = y[train_index], y[val_index]\n",
    "  f1_scores.append(one_fold(X_train, y_train, X_val, y_val, batch_size = 256, epochs=5, es=es) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbEaeJzAjhN3",
    "outputId": "2af1caa1-748f-496d-ed3b-26f37c52213f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5436117094096132,\n",
       " 0.5417195567912453,\n",
       " 0.539556615379076,\n",
       " 0.5448144874069515,\n",
       " 0.5448732535049198]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NM7l852u4jtk",
    "outputId": "df5c62a4-e534-4b7f-b546-8bfa46011f8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5429151244983611"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2VOJ3GvjhLY"
   },
   "outputs": [],
   "source": [
    "# import baseline f1_score\n",
    "import pickle\n",
    "with open(\"/content/drive/My Drive/Colab Notebooks/Group Project/lstm_baseline.txt\", \"rb\") as fp:\n",
    "   lstm_baseline = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GjN6z_0cjhGB",
    "outputId": "b51a3300-4f46-40af-cab4-42f757fb4d20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=4.986960133017524, pvalue=0.007559925790954875)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t-test\n",
    "from scipy import stats\n",
    "stats.ttest_rel(lstm_baseline, f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SYQIXMcjhCk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vb17TDesjg_J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8Vut-hLjg8C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "(FINAL) LSTM+Glove (Hypothesis - Nig)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
