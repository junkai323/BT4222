{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEa_RQw_0NyS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.layers import Dropout, SpatialDropout1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Conv2D\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g0iaKg81QyG"
   },
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VkIfieB13WG",
    "outputId": "885106af-4bb0-4606-96ab-441ba1ca399e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qu1CI9ex1TB4"
   },
   "outputs": [],
   "source": [
    "full_clean_df = pd.read_excel(\"../data/full_clean_df.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mYbxrImx0ebe"
   },
   "outputs": [],
   "source": [
    "labels_name_list = ['NotHate', 'Racist', 'Sexist', 'Homophobe', 'Religion', 'OtherHate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSn9K0pa93qg",
    "outputId": "67c3c61e-e7b1-4240-9399-5299d4911f28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length of tweet\n",
    "max([len(i) for i in full_clean_df['tweets_emoji_train'].apply(lambda x: x.split(' '))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmPwKkuE2LfA"
   },
   "source": [
    "**Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZ2GFYyk2KwK"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(full_clean_df['tweets_emoji_train'], np.array(full_clean_df[labels_name_list]), test_size=0.33, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNdRrZZxhxUp"
   },
   "outputs": [],
   "source": [
    "X = X_train\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AW0j6vEignM8",
    "outputId": "c368fb74-b5ab-46ba-e842-610b429ef16c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95995,)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHHQ-NjsggQ2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vj1N4-4REDsu"
   },
   "source": [
    "Define function to plot history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rbe8YuZG2X9W"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # Plot loss and AUC \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.epoch, history.history['val_loss'], 'g-', label='Validation data')\n",
    "    plt.plot(history.epoch, history.history['loss'], 'r--', label='Training data')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Loss on training/validation data')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.epoch, history.history['val_auc'], 'g-', label='Validation data')\n",
    "    plt.plot(history.epoch, history.history['auc'], 'r--', label='Training data')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('AUC on training/validation data')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Co5TgclfAW9j"
   },
   "outputs": [],
   "source": [
    "# Tokenize Text (Represent each word by a number)\n",
    "max_features = 10000\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# Keep all tweets to exact 65 words\n",
    "maxlen = 65\n",
    "\n",
    "train_encoded = tokenizer.texts_to_sequences(X)\n",
    "train_padded = sequence.pad_sequences(train_encoded, maxlen=maxlen)\n",
    "\n",
    "test_encoded = tokenizer.texts_to_sequences(X_test)\n",
    "test_padded = sequence.pad_sequences(test_encoded, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5031vd-LB6m7",
    "outputId": "b87276ab-40ab-4041-890d-66945635b890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-21 13:45:58--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
      "--2021-04-21 13:45:58--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
      "--2021-04-21 13:45:59--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1520408563 (1.4G) [application/zip]\n",
      "Saving to: ‘glove.twitter.27B.zip’\n",
      "\n",
      "glove.twitter.27B.z 100%[===================>]   1.42G  5.17MB/s    in 4m 52s  \n",
      "\n",
      "2021-04-21 13:50:50 (4.97 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-21ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
      "Archive:  glove.twitter.27B.zip\n",
      "  inflating: glove.twitter.27B.25d.txt  \n",
      "  inflating: glove.twitter.27B.50d.txt  \n",
      "  inflating: glove.twitter.27B.100d.txt  \n",
      "  inflating: glove.twitter.27B.200d.txt  \n"
     ]
    }
   ],
   "source": [
    "# Install gloVe twitter\n",
    "\n",
    "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "!sudo apt install unzip\n",
    "!unzip glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1tNQNilAW66"
   },
   "outputs": [],
   "source": [
    "# Load the embedding file\n",
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "EMBEDDING_FILE = 'glove.twitter.27B.100d.txt'\n",
    "# Map each word to its word vector\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, 'r', encoding='UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZBEyUsTAW48",
    "outputId": "099c90d9-9b25-4ca4-e9db-337a1bbde890"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "#change below line if computing normal stats is too slow\n",
    "embedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg7fMUnkXJt4"
   },
   "source": [
    "# 5-folds Cross Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8JRj5QPX1q1"
   },
   "source": [
    "**Function to compile Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMC1anTwRrlR"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 5\n",
    "embed_size = 100\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWj-xgG-RwrQ"
   },
   "outputs": [],
   "source": [
    "def compile_model(max_features=max_features, embed_size=100, embedding_matrix=embedding_matrix, maxlen=maxlen):\n",
    "  # Define the Neural Network\n",
    "  model = Sequential()\n",
    "  # Non-trainable embeddidng layer\n",
    "  model.add(Embedding(max_features, output_dim=embed_size, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
    "  # LSTM \n",
    "  model.add(LSTM(128, return_sequences=True))\n",
    "  model.add(Dropout(0.15))\n",
    "  model.add(LSTM(64))\n",
    "  model.add(Dropout(0.15))\n",
    "  model.add(Dense(6, activation='sigmoid'))\n",
    "  model.summary()\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Precision', 'Recall', 'AUC'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rKhDooTYYRt"
   },
   "outputs": [],
   "source": [
    "def one_fold(X_train, y_train, X_val, y_val, batch_size, epochs, es):\n",
    "  model = compile_model()\n",
    "\n",
    "  history = model.fit(X_train, y_train, batch_size = batch_size, validation_data = (X_val, y_val), epochs=epochs, callbacks=[es])\n",
    "  y_pred = model.predict(X_val)\n",
    "  predictions = [[1 if i >=0.3 else 0 for i in pred] for pred in y_pred]\n",
    "\n",
    "  score = metrics.f1_score(y_val, predictions, average='macro')\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MfkCW0ZeaJ1i",
    "outputId": "e4b41c9d-c559-440d-a09a-17169a122925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 65, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 65, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 40s 21ms/step - loss: 0.3506 - precision: 0.8526 - recall: 0.5992 - auc: 0.8795 - val_loss: 0.2741 - val_precision: 0.8772 - val_recall: 0.6653 - val_auc: 0.9323\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 5s 17ms/step - loss: 0.2794 - precision: 0.8550 - recall: 0.6794 - auc: 0.9293 - val_loss: 0.2664 - val_precision: 0.8651 - val_recall: 0.6898 - val_auc: 0.9360\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2703 - precision: 0.8643 - recall: 0.6890 - auc: 0.9334 - val_loss: 0.2617 - val_precision: 0.8814 - val_recall: 0.6836 - val_auc: 0.9380\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2660 - precision: 0.8697 - recall: 0.6902 - auc: 0.9356 - val_loss: 0.2600 - val_precision: 0.8765 - val_recall: 0.6900 - val_auc: 0.9390\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2637 - precision: 0.8728 - recall: 0.6898 - auc: 0.9373 - val_loss: 0.2608 - val_precision: 0.8760 - val_recall: 0.6869 - val_auc: 0.9386\n",
      "Epoch 00005: early stopping\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 65, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 65, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 9s 21ms/step - loss: 0.3490 - precision: 0.8681 - recall: 0.5952 - auc: 0.8802 - val_loss: 0.2765 - val_precision: 0.8963 - val_recall: 0.6397 - val_auc: 0.9310\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2776 - precision: 0.8536 - recall: 0.6828 - auc: 0.9302 - val_loss: 0.2646 - val_precision: 0.8732 - val_recall: 0.6885 - val_auc: 0.9365\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2701 - precision: 0.8633 - recall: 0.6884 - auc: 0.9339 - val_loss: 0.2613 - val_precision: 0.8780 - val_recall: 0.6872 - val_auc: 0.9380\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2674 - precision: 0.8690 - recall: 0.6879 - auc: 0.9351 - val_loss: 0.2596 - val_precision: 0.8841 - val_recall: 0.6843 - val_auc: 0.9388\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2633 - precision: 0.8734 - recall: 0.6868 - auc: 0.9373 - val_loss: 0.2589 - val_precision: 0.8901 - val_recall: 0.6786 - val_auc: 0.9391\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 65, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 65, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 10s 21ms/step - loss: 0.3528 - precision: 0.8568 - recall: 0.5810 - auc: 0.8735 - val_loss: 0.2838 - val_precision: 0.8489 - val_recall: 0.6743 - val_auc: 0.9272\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2782 - precision: 0.8483 - recall: 0.6877 - auc: 0.9299 - val_loss: 0.2726 - val_precision: 0.8716 - val_recall: 0.6758 - val_auc: 0.9326\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2702 - precision: 0.8560 - recall: 0.6922 - auc: 0.9338 - val_loss: 0.2691 - val_precision: 0.8696 - val_recall: 0.6829 - val_auc: 0.9344\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2667 - precision: 0.8682 - recall: 0.6884 - auc: 0.9355 - val_loss: 0.2674 - val_precision: 0.8781 - val_recall: 0.6772 - val_auc: 0.9352\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2633 - precision: 0.8716 - recall: 0.6906 - auc: 0.9371 - val_loss: 0.2657 - val_precision: 0.8800 - val_recall: 0.6778 - val_auc: 0.9362\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 65, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 65, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 10s 21ms/step - loss: 0.3602 - precision: 0.8600 - recall: 0.5738 - auc: 0.8698 - val_loss: 0.2821 - val_precision: 0.8850 - val_recall: 0.6372 - val_auc: 0.9283\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2812 - precision: 0.8467 - recall: 0.6811 - auc: 0.9283 - val_loss: 0.2689 - val_precision: 0.8599 - val_recall: 0.6940 - val_auc: 0.9349\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2708 - precision: 0.8559 - recall: 0.6934 - auc: 0.9336 - val_loss: 0.2673 - val_precision: 0.8827 - val_recall: 0.6755 - val_auc: 0.9359\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2672 - precision: 0.8641 - recall: 0.6909 - auc: 0.9352 - val_loss: 0.2635 - val_precision: 0.8938 - val_recall: 0.6679 - val_auc: 0.9376\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2639 - precision: 0.8745 - recall: 0.6870 - auc: 0.9366 - val_loss: 0.2619 - val_precision: 0.8825 - val_recall: 0.6806 - val_auc: 0.9382\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 65, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 65, 128)           117248    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 1,167,046\n",
      "Trainable params: 167,046\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "300/300 [==============================] - 10s 22ms/step - loss: 0.3588 - precision: 0.8428 - recall: 0.5880 - auc: 0.8715 - val_loss: 0.2781 - val_precision: 0.8642 - val_recall: 0.6619 - val_auc: 0.9303\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2783 - precision: 0.8481 - recall: 0.6837 - auc: 0.9298 - val_loss: 0.2683 - val_precision: 0.8661 - val_recall: 0.6849 - val_auc: 0.9351\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 6s 18ms/step - loss: 0.2706 - precision: 0.8572 - recall: 0.6930 - auc: 0.9339 - val_loss: 0.2661 - val_precision: 0.8713 - val_recall: 0.6842 - val_auc: 0.9363\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2646 - precision: 0.8681 - recall: 0.6932 - auc: 0.9364 - val_loss: 0.2637 - val_precision: 0.8908 - val_recall: 0.6704 - val_auc: 0.9376\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 5s 18ms/step - loss: 0.2623 - precision: 0.8725 - recall: 0.6920 - auc: 0.9377 - val_loss: 0.2621 - val_precision: 0.8800 - val_recall: 0.6819 - val_auc: 0.9382\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_padded):\n",
    "  X_train, X_val = train_padded[train_index], train_padded[val_index]\n",
    "  y_train, y_val = y[train_index], y[val_index]\n",
    "  f1_scores.append(one_fold(X_train, y_train, X_val, y_val, batch_size = 256, epochs=5, es=es) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbEaeJzAjhN3",
    "outputId": "12bed4b0-60b2-4e14-ad2f-483530f6ad78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5431816667658715,\n",
       " 0.5494429994525477,\n",
       " 0.5395992321454626,\n",
       " 0.5496570832621102,\n",
       " 0.5513926961957929]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EV0rCNNA5BKw",
    "outputId": "c370b4a6-a776-4a06-c582-f76071667713"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.546654735564357"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2VOJ3GvjhLY"
   },
   "outputs": [],
   "source": [
    "# import baseline f1_score\n",
    "import pickle\n",
    "with open(\"/content/drive/My Drive/BT4222/FINAL_CODES/lstm_baseline.txt\", \"rb\") as fp:\n",
    "   lstm_baseline = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Y4Fdgc1jhIJ",
    "outputId": "5f795617-2881-4b47-8cef-5531a01a0609"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5503131007793429,\n",
       " 0.5536645807247731,\n",
       " 0.543105274882358,\n",
       " 0.5556589535657163,\n",
       " 0.5508641887640409]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoUz9aA55znx",
    "outputId": "c1763343-6275-49da-b0c0-d77f7bf4848b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5507212197432463"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(lstm_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GjN6z_0cjhGB",
    "outputId": "9d62c42b-6369-4693-e031-6836ad45bd05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=3.0920600165451826, pvalue=0.0365012356527156)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t-test\n",
    "from scipy import stats\n",
    "stats.ttest_rel(lstm_baseline, f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SYQIXMcjhCk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vb17TDesjg_J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8Vut-hLjg8C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "(FINAL) LSTM+Glove (Hypothesis - Emoji)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
