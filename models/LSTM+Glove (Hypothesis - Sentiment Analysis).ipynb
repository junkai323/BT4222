{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 836,
     "status": "ok",
     "timestamp": 1619069599166,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "IEa_RQw_0NyS",
    "outputId": "118211f7-1521-47ed-e5d2-e142dff233be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import division\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Concatenate, Input, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import logging\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g0iaKg81QyG"
   },
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17378,
     "status": "ok",
     "timestamp": 1619068416032,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "1VkIfieB13WG",
    "outputId": "5f80d7ef-ca6e-432a-b90d-aa1107c386f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 15633,
     "status": "ok",
     "timestamp": 1619068456238,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "Qu1CI9ex1TB4"
   },
   "outputs": [],
   "source": [
    "full_clean_df = pd.read_excel(\"../data/full_clean_df.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1619068460076,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "mYbxrImx0ebe"
   },
   "outputs": [],
   "source": [
    "labels_name_list = ['NotHate', 'Racist', 'Sexist', 'Homophobe', 'Religion', 'OtherHate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1619068470997,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "FxlOS894R21Q",
    "outputId": "83ca97da-ea31-4e0b-870b-4e4f3daaf4ee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>NotHate</th>\n",
       "      <th>Racist</th>\n",
       "      <th>Sexist</th>\n",
       "      <th>Homophobe</th>\n",
       "      <th>Religion</th>\n",
       "      <th>OtherHate</th>\n",
       "      <th>tweets_train</th>\n",
       "      <th>tweets_emoji_train</th>\n",
       "      <th>tweets_nig_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nigga momma youngboy spit real shit nigga</td>\n",
       "      <td>nigga momma youngboy spit real shit nigga</td>\n",
       "      <td>momma youngboy spit real shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>xxsugvngxx ran holy nigga today</td>\n",
       "      <td>xxsugvngxx ran holy nigga today loudly_crying_...</td>\n",
       "      <td>xxsugvngxx ran holy  today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“EVERYbody calling you Nigger now!” https://t....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody call nigger</td>\n",
       "      <td>everybody call nigger</td>\n",
       "      <td>everybody call nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“ real ass bitch give a fuck boutta nigga” htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>real bitch give fuck boutta nigga</td>\n",
       "      <td>real bitch give fuck boutta nigga</td>\n",
       "      <td>real bitch give fuck boutta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@WhiteHouse @realDonaldTrump Fuck ice. White s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fuck ice white supremacist trash racist garbage</td>\n",
       "      <td>fuck ice white supremacist trash racist garbage</td>\n",
       "      <td>fuck ice white supremacist trash racist garbage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  ...                                 tweets_nig_train\n",
       "0  “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...  ...                    momma youngboy spit real shit\n",
       "1  RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...  ...                       xxsugvngxx ran holy  today\n",
       "2  “EVERYbody calling you Nigger now!” https://t....  ...                            everybody call nigger\n",
       "3  “ real ass bitch give a fuck boutta nigga” htt...  ...                      real bitch give fuck boutta\n",
       "4  @WhiteHouse @realDonaldTrump Fuck ice. White s...  ...  fuck ice white supremacist trash racist garbage\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_clean_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1175,
     "status": "ok",
     "timestamp": 1619068465149,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "JSn9K0pa93qg",
    "outputId": "2889f4ba-201b-4418-ecc6-67d1bedd2f3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max length of tweet\n",
    "max([len(i) for i in full_clean_df['tweets_train'].apply(lambda x: x.split(' '))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuXurYHaAFYa"
   },
   "source": [
    "## Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1619068960908,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "IZ-dmZqWADUK"
   },
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 14863,
     "status": "ok",
     "timestamp": 1619068976372,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "NT7ZHjOUAV4_"
   },
   "outputs": [],
   "source": [
    "full_clean_df['sentiment'] = full_clean_df['tweets_train'].apply(lambda x: sia.polarity_scores(x).get('compound'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1619068981322,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "RcayOBqCAV3J",
    "outputId": "e74e6ddd-f5dc-496b-ecc5-fae8f8147eb6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>NotHate</th>\n",
       "      <th>Racist</th>\n",
       "      <th>Sexist</th>\n",
       "      <th>Homophobe</th>\n",
       "      <th>Religion</th>\n",
       "      <th>OtherHate</th>\n",
       "      <th>tweets_train</th>\n",
       "      <th>tweets_emoji_train</th>\n",
       "      <th>tweets_nig_train</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nigga momma youngboy spit real shit nigga</td>\n",
       "      <td>nigga momma youngboy spit real shit nigga</td>\n",
       "      <td>momma youngboy spit real shit</td>\n",
       "      <td>-0.5574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>xxsugvngxx ran holy nigga today</td>\n",
       "      <td>xxsugvngxx ran holy nigga today loudly_crying_...</td>\n",
       "      <td>xxsugvngxx ran holy  today</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“EVERYbody calling you Nigger now!” https://t....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody call nigger</td>\n",
       "      <td>everybody call nigger</td>\n",
       "      <td>everybody call nigger</td>\n",
       "      <td>-0.6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“ real ass bitch give a fuck boutta nigga” htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>real bitch give fuck boutta nigga</td>\n",
       "      <td>real bitch give fuck boutta nigga</td>\n",
       "      <td>real bitch give fuck boutta</td>\n",
       "      <td>-0.8074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@WhiteHouse @realDonaldTrump Fuck ice. White s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>fuck ice white supremacist trash racist garbage</td>\n",
       "      <td>fuck ice white supremacist trash racist garbage</td>\n",
       "      <td>fuck ice white supremacist trash racist garbage</td>\n",
       "      <td>-0.7906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  ...  sentiment\n",
       "0  “NIGGA ON MA MOMMA YOUNGBOY BE SPITTING REAL S...  ...    -0.5574\n",
       "1  RT xxSuGVNGxx: I ran into this HOLY NIGGA TODA...  ...     0.0000\n",
       "2  “EVERYbody calling you Nigger now!” https://t....  ...    -0.6486\n",
       "3  “ real ass bitch give a fuck boutta nigga” htt...  ...    -0.8074\n",
       "4  @WhiteHouse @realDonaldTrump Fuck ice. White s...  ...    -0.7906\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PiMfmMV1AVzE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmPwKkuE2LfA"
   },
   "source": [
    "**Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1619068986407,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "h_lscEOe5Ric"
   },
   "outputs": [],
   "source": [
    "train_cols = ['tweets_train', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1619070489699,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "nZ2GFYyk2KwK"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(full_clean_df[train_cols], full_clean_df[labels_name_list], test_size=0.33, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1619069022292,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "c2KfjIXx2V4N",
    "outputId": "1cdc5dfe-b47d-4d26-c3a9-632769652924"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95995, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vj1N4-4REDsu"
   },
   "source": [
    "Define function to plot history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1619069025780,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "Rbe8YuZG2X9W"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # Plot loss and AUC \n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.epoch, history.history['val_loss'], 'g-', label='Validation data')\n",
    "    plt.plot(history.epoch, history.history['loss'], 'r--', label='Training data')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Loss on training/validation data')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.plot(history.epoch, history.history['val_auc'], 'g-', label='Validation data')\n",
    "    plt.plot(history.epoch, history.history['auc'], 'r--', label='Training data')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('AUC on training/validation data')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6WJ3SCtmxDZ"
   },
   "source": [
    "## Pre-Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opQtVnwmm7o5"
   },
   "source": [
    "Tokenize and Pad Tweets only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1619070427079,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "MPElBDLYU0_5"
   },
   "outputs": [],
   "source": [
    "X_train_tweets = X_train['tweets_train']\n",
    "X_test_tweets = X_test['tweets_train']\n",
    "X_val_tweets = X_val['tweets_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1619070494311,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "a1B7SDQtcHVV"
   },
   "outputs": [],
   "source": [
    "train_sa = np.array(X_train['sentiment'])\n",
    "test_sa = np.array(X_test['sentiment'])\n",
    "val_sa = np.array(X_val['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1619070495619,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "8O_KBJ5tEymM"
   },
   "outputs": [],
   "source": [
    "y = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 3970,
     "status": "ok",
     "timestamp": 1619070502648,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "BwWTAU4-UFZY"
   },
   "outputs": [],
   "source": [
    "# Tokenize Text (Represent each word by a number)\n",
    "max_features = 10000\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X_train_tweets)\n",
    "\n",
    "# Keep all tweets to exactly 25 words\n",
    "maxlen = 25\n",
    "\n",
    "train_encoded = tokenizer.texts_to_sequences(X_train_tweets)\n",
    "train_padded = sequence.pad_sequences(train_encoded, maxlen=maxlen)\n",
    "\n",
    "test_encoded = tokenizer.texts_to_sequences(X_test_tweets)\n",
    "test_padded = sequence.pad_sequences(test_encoded, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6Fl2msEVEFp"
   },
   "source": [
    "## Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358824,
     "status": "ok",
     "timestamp": 1619069426326,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "5031vd-LB6m7",
    "outputId": "49265965-2996-4e68-d14a-388cf8ea3c75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-22 05:24:28--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
      "--2021-04-22 05:24:28--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
      "--2021-04-22 05:24:28--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1520408563 (1.4G) [application/zip]\n",
      "Saving to: ‘glove.twitter.27B.zip’\n",
      "\n",
      "glove.twitter.27B.z 100%[===================>]   1.42G  5.16MB/s    in 4m 49s  \n",
      "\n",
      "2021-04-22 05:29:18 (5.01 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-21ubuntu1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
      "Archive:  glove.twitter.27B.zip\n",
      "  inflating: glove.twitter.27B.25d.txt  \n",
      "  inflating: glove.twitter.27B.50d.txt  \n",
      "  inflating: glove.twitter.27B.100d.txt  \n",
      "  inflating: glove.twitter.27B.200d.txt  \n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
    "!sudo apt install unzip\n",
    "!unzip glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 31154,
     "status": "ok",
     "timestamp": 1619069486608,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "C1tNQNilAW66"
   },
   "outputs": [],
   "source": [
    "# Load the embedding file\n",
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "EMBEDDING_FILE = 'glove.twitter.27B.100d.txt'\n",
    "# Map each word to its word vector\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, 'r', encoding='UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18888,
     "status": "ok",
     "timestamp": 1619069488757,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "_ZBEyUsTAW48",
    "outputId": "34b6ffc4-6388-40c0-e892-f362b2b742b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index)+1)\n",
    "\n",
    "#change below line if computing normal stats is too slow\n",
    "embedding_matrix = embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DywjWKRBhIf"
   },
   "source": [
    "# 5-folds Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 884,
     "status": "ok",
     "timestamp": 1619069518208,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "rMC1anTwRrlR"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 5\n",
    "embed_size = 100\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQH4jBgHCpRZ"
   },
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1619070505790,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "aNrJoaiTVVLO"
   },
   "outputs": [],
   "source": [
    "def compile_model(max_features=max_features, embed_size=embed_size, embedding_matrix=embedding_matrix, maxlen=maxlen):\n",
    "  nlp_input = Input(shape=(maxlen,), name='nlp_input') # tweets input\n",
    "  meta_input = Input(shape=(1,), name='meta_input') # sentiment analysis input\n",
    "\n",
    "  # EMBEDDING\n",
    "  emb = Embedding(output_dim=embed_size, input_dim=max_features, weights=[embedding_matrix], input_length=maxlen, trainable=False)(nlp_input)\n",
    "\n",
    "  # LSTM\n",
    "  nlp_out = Bidirectional(LSTM(128, dropout=0.3, recurrent_dropout=0.3))(emb)\n",
    "\n",
    "  # CONCAT LAYER\n",
    "  conc = Concatenate()([nlp_out, meta_input])\n",
    "  dense1 = Dense(64, activation='relu')(conc)\n",
    "  out = Dense(6, activation='sigmoid')(dense1)\n",
    "  model = keras.Model(inputs=[nlp_input , meta_input], outputs=out)\n",
    "\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Precision', 'Recall', 'AUC'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 631,
     "status": "ok",
     "timestamp": 1619070844279,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "S0E2MowSBg6l"
   },
   "outputs": [],
   "source": [
    "def one_fold(X_train_padded, X_train_sa, y_train, X_val_padded, X_val_sa, y_val, batch_size, epochs, es):\n",
    "  model = compile_model()\n",
    "\n",
    "  history = model.fit(x=[X_train_padded, X_train_sa], y=y_train, validation_data=([X_val_padded, X_val_sa], y_val), batch_size=batch_size, epochs=epochs, callbacks=[es])\n",
    "  y_pred = model.predict([X_val_padded,  X_val_sa])\n",
    "  predictions = [[1 if i >=0.3 else 0 for i in pred] for pred in y_pred]\n",
    "\n",
    "  score = metrics.f1_score(y_val, predictions, average='macro')\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1456622,
     "status": "ok",
     "timestamp": 1619072305399,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "omlUP5UTBg2p",
    "outputId": "3907982d-2aa6-4ea0-fe22-b5443201aa8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 60s 184ms/step - loss: 0.3338 - precision: 0.8491 - recall: 0.6097 - auc: 0.8937 - val_loss: 0.2704 - val_precision: 0.8815 - val_recall: 0.6727 - val_auc: 0.9338\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 55s 182ms/step - loss: 0.2753 - precision: 0.8634 - recall: 0.6766 - auc: 0.9313 - val_loss: 0.2639 - val_precision: 0.8843 - val_recall: 0.6782 - val_auc: 0.9369\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 55s 182ms/step - loss: 0.2680 - precision: 0.8708 - recall: 0.6831 - auc: 0.9350 - val_loss: 0.2629 - val_precision: 0.8849 - val_recall: 0.6779 - val_auc: 0.9373\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 54s 181ms/step - loss: 0.2649 - precision: 0.8676 - recall: 0.6866 - auc: 0.9365 - val_loss: 0.2615 - val_precision: 0.8598 - val_recall: 0.7001 - val_auc: 0.9386\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 54s 181ms/step - loss: 0.2625 - precision: 0.8789 - recall: 0.6847 - auc: 0.9378 - val_loss: 0.2596 - val_precision: 0.8838 - val_recall: 0.6808 - val_auc: 0.9393\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 61s 187ms/step - loss: 0.3385 - precision: 0.8588 - recall: 0.5931 - auc: 0.8878 - val_loss: 0.2704 - val_precision: 0.8834 - val_recall: 0.6727 - val_auc: 0.9339\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 55s 183ms/step - loss: 0.2727 - precision: 0.8698 - recall: 0.6752 - auc: 0.9326 - val_loss: 0.2648 - val_precision: 0.8904 - val_recall: 0.6729 - val_auc: 0.9365\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 55s 182ms/step - loss: 0.2670 - precision: 0.8740 - recall: 0.6827 - auc: 0.9359 - val_loss: 0.2614 - val_precision: 0.8752 - val_recall: 0.6923 - val_auc: 0.9382\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 55s 182ms/step - loss: 0.2633 - precision: 0.8758 - recall: 0.6833 - auc: 0.9375 - val_loss: 0.2603 - val_precision: 0.8610 - val_recall: 0.7027 - val_auc: 0.9388\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 55s 182ms/step - loss: 0.2636 - precision: 0.8740 - recall: 0.6860 - auc: 0.9374 - val_loss: 0.2581 - val_precision: 0.8735 - val_recall: 0.6951 - val_auc: 0.9398\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 60s 186ms/step - loss: 0.3359 - precision: 0.8545 - recall: 0.6042 - auc: 0.8899 - val_loss: 0.2774 - val_precision: 0.8394 - val_recall: 0.6993 - val_auc: 0.9303\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 55s 184ms/step - loss: 0.2724 - precision: 0.8706 - recall: 0.6780 - auc: 0.9326 - val_loss: 0.2712 - val_precision: 0.8601 - val_recall: 0.6878 - val_auc: 0.9335\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 56s 187ms/step - loss: 0.2685 - precision: 0.8698 - recall: 0.6834 - auc: 0.9349 - val_loss: 0.2696 - val_precision: 0.8795 - val_recall: 0.6744 - val_auc: 0.9343\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 56s 188ms/step - loss: 0.2626 - precision: 0.8780 - recall: 0.6829 - auc: 0.9378 - val_loss: 0.2668 - val_precision: 0.8768 - val_recall: 0.6791 - val_auc: 0.9359\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 58s 193ms/step - loss: 0.2596 - precision: 0.8810 - recall: 0.6862 - auc: 0.9394 - val_loss: 0.2652 - val_precision: 0.8756 - val_recall: 0.6813 - val_auc: 0.9366\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 62s 193ms/step - loss: 0.3433 - precision: 0.8342 - recall: 0.6070 - auc: 0.8861 - val_loss: 0.2736 - val_precision: 0.8702 - val_recall: 0.6773 - val_auc: 0.9324\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 58s 192ms/step - loss: 0.2732 - precision: 0.8690 - recall: 0.6751 - auc: 0.9326 - val_loss: 0.2674 - val_precision: 0.8820 - val_recall: 0.6762 - val_auc: 0.9358\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 57s 190ms/step - loss: 0.2680 - precision: 0.8733 - recall: 0.6803 - auc: 0.9352 - val_loss: 0.2643 - val_precision: 0.8577 - val_recall: 0.7024 - val_auc: 0.9374\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 58s 193ms/step - loss: 0.2651 - precision: 0.8730 - recall: 0.6865 - auc: 0.9369 - val_loss: 0.2641 - val_precision: 0.8895 - val_recall: 0.6748 - val_auc: 0.9377\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 56s 187ms/step - loss: 0.2609 - precision: 0.8777 - recall: 0.6872 - auc: 0.9388 - val_loss: 0.2615 - val_precision: 0.8817 - val_recall: 0.6841 - val_auc: 0.9384\n",
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 61s 185ms/step - loss: 0.3423 - precision: 0.8391 - recall: 0.5976 - auc: 0.8843 - val_loss: 0.2768 - val_precision: 0.8783 - val_recall: 0.6625 - val_auc: 0.9313\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 56s 186ms/step - loss: 0.2756 - precision: 0.8623 - recall: 0.6780 - auc: 0.9315 - val_loss: 0.2667 - val_precision: 0.8728 - val_recall: 0.6826 - val_auc: 0.9359\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 56s 187ms/step - loss: 0.2682 - precision: 0.8702 - recall: 0.6837 - auc: 0.9351 - val_loss: 0.2642 - val_precision: 0.8733 - val_recall: 0.6845 - val_auc: 0.9372\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 56s 185ms/step - loss: 0.2637 - precision: 0.8718 - recall: 0.6888 - auc: 0.9375 - val_loss: 0.2631 - val_precision: 0.8706 - val_recall: 0.6874 - val_auc: 0.9378\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 56s 186ms/step - loss: 0.2610 - precision: 0.8752 - recall: 0.6875 - auc: 0.9389 - val_loss: 0.2620 - val_precision: 0.8738 - val_recall: 0.6877 - val_auc: 0.9382\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(train_padded):\n",
    "  X_train_padded, X_val_padded = train_padded[train_index], train_padded[val_index]\n",
    "  X_train_sa, X_val_sa = train_sa[train_index], train_sa[val_index]\n",
    "  y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "  f1_scores.append(one_fold(X_train_padded, X_train_sa, y_train, X_val_padded, X_val_sa, y_val, batch_size=batch_size, epochs=5, es=es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1619072310609,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "t8InsaahBgsy",
    "outputId": "46636c10-6b74-4326-ec4a-07328f962cf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5477645505053437,\n",
       " 0.5531480161605454,\n",
       " 0.553671417445957,\n",
       " 0.5541537512971975,\n",
       " 0.5538317701748637]"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1619072315577,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "sizOTugcH3El",
    "outputId": "a6551af8-8f96-4198-e2fb-9b428d606494"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5525139011167813"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1619072317312,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "Kebk2a3ZH3B6"
   },
   "outputs": [],
   "source": [
    "# import baseline f1_score\n",
    "import pickle\n",
    "with open(\"/content/drive/My Drive/Colab Notebooks/Group Project/lstm_baseline.txt\", \"rb\") as fp:\n",
    "   lstm_baseline = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1619072318509,
     "user": {
      "displayName": "Julene Gatot",
      "photoUrl": "",
      "userId": "07460675129096291951"
     },
     "user_tz": -480
    },
    "id": "Pr7ypA8gsUtM",
    "outputId": "bd7184d6-38b7-41f7-dd61-55eb754ab946"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-0.7528256814627696, pvalue=0.4934360031621986)"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t-test\n",
    "from scipy import stats\n",
    "stats.ttest_rel(lstm_baseline, f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZCai6qoL4fc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "(FINAL) LSTM+Glove Twitter (Sentiment Analysis).ipynb",
   "provenance": [
    {
     "file_id": "1vi8QGsUecUoKDpaiLU2xVHwDAEmcj269",
     "timestamp": 1617424550412
    },
    {
     "file_id": "1EnIarqKf9PInhtZEmFrrf8fyuwtxQFTf",
     "timestamp": 1617417028549
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
